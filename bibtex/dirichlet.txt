@InProceedings{pmlr-v235-stark24b,
    title = 	 {{D}irichlet Flow Matching with Applications to {DNA} Sequence Design},
    author =       {Stark, Hannes and Jing, Bowen and Wang, Chenyu and Corso, Gabriele and Berger, Bonnie and Barzilay, Regina and Jaakkola, Tommi},
    booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
    pages = 	 {46495--46513},
    year = 	 {2024},
    editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
    volume = 	 {235},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {21--27 Jul},
    publisher =    {PMLR},
    pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/stark24b/stark24b.pdf},
    url = 	 {https://proceedings.mlr.press/v235/stark24b.html},
    abstract = 	 {Discrete diffusion or flow models could enable faster and more controllable sequence generation than autoregressive models. We show that naive linear flow matching on the simplex is insufficient toward this goal since it suffers from discontinuities in the training target and further pathologies. To overcome this, we develop Dirichlet flow matching on the simplex based on mixtures of Dirichlet distributions as probability paths. In this framework, we derive a connection between the mixtures’ scores and the flow’s vector field that allows for classifier and classifier-free guidance. Further, we provide distilled Dirichlet flow matching, which enables one-step sequence generation with minimal performance hits, resulting in $O(L)$ speedups compared to autoregressive models. On complex DNA sequence generation tasks, we demonstrate superior performance compared to all baselines in distributional metrics and in achieving desired design targets for generated sequences. Finally, we show that our classifier-free guidance approach improves unconditional generation and is effective for generating DNA that satisfies design targets.}
}
